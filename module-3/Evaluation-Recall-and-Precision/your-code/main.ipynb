{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = mnist['data'], mnist['target']\n",
    "\n",
    "X.shape # (70000, 784)  # X INPUT all the features of the handwritten number (70000 rows, 784 columns)\n",
    "y.shape # (70000,)      # Y is the TARGET ( the actual number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ee2ae50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[36000].reshape(28,28), cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[36000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X are the features we use as input for the model (60k rows in total)\n",
    "\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]  \n",
    "\n",
    "# Y is the expected outcome/label (10k rows in total)\n",
    "\n",
    "y_train= y[:60000]\n",
    "y_test = y[60000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '0', '4', ..., '5', '6', '8'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does y looks like? \n",
    "\n",
    "y_train # The outcome we need , which is the actual number from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make the target (y_test & y_train ) binary 5=1 and other numbers = 0\n",
    "\n",
    "y_train5 = np.where(y_train == '5', 1 , 0)\n",
    "y_test5 = np.where(y_test == '5', 1 , 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# X_train = all the features / index [0:60000]\n",
    "# y_train5 = outcome / Binary version/ All 5's areâ€™ 1 and other numbers are 0\n",
    "\n",
    "find5_model = LogisticRegression().fit(X_train, y_train5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train[36000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Yes the output is 0 because the 36000th digit is not the number 5\n",
    "\n",
    "find5_model.predict(X_train[36000].reshape(1,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None): # doesn't do anyhting\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9108    0]\n",
      " [ 892    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9108"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Fit the model\n",
    "never5_model = never_5_clf.fit(X_train, y_train5)\n",
    "\n",
    "# predictions\n",
    "y_pred_test2 =  Never5Classifier().predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test5,y_pred_test2))\n",
    "\n",
    "# 9108 true negative\n",
    "# 892  false positive , were 5 but classified as not 5\n",
    "\n",
    "accuracy2 = 9108 / (9108 + 892)\n",
    "\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[9034   74]\n",
      " [ 147  745]] \n",
      "\n",
      "Accuracy: 0.9779 \n",
      "\n",
      "Precision: 0.9096459096459096 \n",
      "\n",
      "Recall/Sensitivity: 0.8352017937219731 \n",
      "\n",
      "F1-Score: 0.8708357685563999 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.4/libexec/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# FIND 5 MODEL \n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# MODEL & PREDICTIONS\n",
    "\n",
    "\n",
    "find5_model = LogisticRegression().fit(X_train, y_train5)\n",
    "y_pred_test =  find5_model.predict(X_test)\n",
    "\n",
    "\n",
    "# EVALUATION\n",
    "\n",
    "print('Confusion Matrix:','\\n', confusion_matrix(y_test5, y_pred_test),'\\n')\n",
    "\n",
    "accuracy = (9034 + 745) / (9034+ 745 +147 +74)\n",
    "\n",
    "print('Accuracy:', accuracy,'\\n')\n",
    "\n",
    "print('Precision:', precision_score(y_test5, y_pred_test), '\\n')\n",
    "\n",
    "print('Recall/Sensitivity:', recall_score(y_test5, y_pred_test), '\\n')\n",
    "\n",
    "print('F1-Score:', f1_score(y_test5, y_pred_test),  '\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[9108    0]\n",
      " [ 892    0]] \n",
      "\n",
      "Accuracy: 0.9108 \n",
      "\n",
      "Precision: 0.0 \n",
      "\n",
      "Recall/Sensitivity: 0.0 \n",
      "\n",
      "F1-Score: 0.0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/2.1.4/libexec/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# NEVER 5 MODEL\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# MODEL & PREDICTIONS\n",
    "\n",
    "\n",
    "#never_5_clf = Never5Classifier()\n",
    "never5_model = never_5_clf.fit(X_train, y_train5)\n",
    "y_pred_test2 = Never5Classifier().predict(X_test)\n",
    "\n",
    "\n",
    "# EVALUATION\n",
    "\n",
    "print('Confusion Matrix:','\\n', confusion_matrix(y_test5, y_pred_test2),'\\n')\n",
    "\n",
    "accuracy = (9108) / (9108+892)\n",
    "\n",
    "print('Accuracy:', accuracy,'\\n')\n",
    "\n",
    "#  Precision = true positives / true positives + false POSITIVES\n",
    "print('Precision:', precision_score(y_test5, y_pred_test2), '\\n')\n",
    "\n",
    "# Recall =  true positives / true positives + false NEGATIVES\n",
    "print('Recall/Sensitivity:', recall_score(y_test5, y_pred_test2), '\\n') # how many TP\n",
    "\n",
    "# Average of precision and recall\n",
    "print('F1-Score:', f1_score(y_test5, y_pred_test2),  '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fisrt model is better that the one that uses always the same output(always not 5).\n",
    "\n",
    "# The first model has 97% accuracy Precision: 0.90, Recall: 0.83, F1-Score: 0.87\n",
    "\n",
    "# The second model(always not 5) it has high accuracy of 91 but zero precision, recall or F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "metrics.plot_roc_curve(find5_model, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135385341029717"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "metrics.roc_auc_score(y_test5, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "NoneType should be a binary classifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d2970c1024ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnever5_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TP Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FP Rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.4/libexec/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.4/libexec/lib/python3.8/site-packages/sklearn/metrics/_plot/roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[0;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     prediction_method = _check_classifer_response_method(estimator,\n",
      "\u001b[0;31mValueError\u001b[0m: NoneType should be a binary classifier"
     ]
    }
   ],
   "source": [
    "fpr, tpr, threshold = plot_roc_curve(never5_model, y_test5, y_pred_test2)\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "ROC curve is better for the first model.\n",
    "\n",
    "\n",
    "Is not good for the second model:\n",
    "ROC is generated by changing the threshold on your predictions and finding the sensitivity and specificity for each threshold. \n",
    "This generally means that as you increase the threshold, \n",
    "your sensitivity decreases but your specificity increases and it draws a picture of the overall quality of your predicted probabilities. \n",
    "In this case, since everything is either 0 or 1 (or very close to it) there are no meaningful thresholds to use.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
