{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Implicit Collaborative Filtering - pos ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from evaluation.ipynb\n",
      "DCG = 0.5\n",
      "IDCG = 1.0\n",
      "nDCG = 0.5\n"
     ]
    }
   ],
   "source": [
    "from evaluation import DCG\n",
    "from evaluation import nDCG\n",
    "from evaluation import R_Precision\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import implicit\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendation and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# FIND SIMILAR ITEMS\n",
    "#---------------------\n",
    "\n",
    "def similar_items(seed_track, top_n):\n",
    "    \"\"\"\n",
    "    input: track_uri\n",
    "    output: top_n recommended track_uris\n",
    "    \"\"\"\n",
    "    track_id = D_track_id[seed_track] \n",
    "    n_similar =  top_n\n",
    "\n",
    "    # Use implicit to get similar items.\n",
    "    similar = model.similar_items(track_id, n_similar)\n",
    "    \n",
    "    similar_i = []\n",
    "    \n",
    "    # Print the names of our most similar artists\n",
    "    for item in similar:\n",
    "        idx, score = item\n",
    "        track_uri = data.track_uri.loc[data.track_uri_id == idx].iloc[0]\n",
    "        #print(data.track_uri.loc[data.track_uri_id == idx].iloc[0], D_desc[track_uri])\n",
    "        similar_i.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "    return similar_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------\n",
    "# FIND SIMILAR ITEMS WITH DESCRIPTION\n",
    "#-------------------------------------\n",
    "\n",
    "def similar_items_with_description(seed_track, top_n):\n",
    "    \"\"\"\n",
    "    input: track_uri\n",
    "    output: top_n recommended track_uris with description as dictionary\n",
    "    \"\"\"\n",
    "    print('CF ALS pos - first track returned is the seed track')\n",
    "    \n",
    "    track_id = D_track_id[seed_track] \n",
    "    n_similar =  top_n+1\n",
    "\n",
    "    # Use implicit to get similar items.\n",
    "    similar = model.similar_items(track_id, n_similar)\n",
    "    \n",
    "    similar_i = {}\n",
    "    \n",
    "    # Print the names of our most similar artists\n",
    "    for item in similar:\n",
    "        idx, score = item\n",
    "        track_uri = data.track_uri.loc[data.track_uri_id == idx].iloc[0]\n",
    "        similar_i[track_uri] = D_desc[track_uri]\n",
    "        #print(data.track_uri.loc[data.track_uri_id == idx].iloc[0], D_desc[track_uri])\n",
    "        #similar_i.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "    return list(similar_i.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "# CREATE USER RECOMMENDATIONS\n",
    "#------------------------------\n",
    "\n",
    "def create_recs(pid,N):\n",
    "    \"\"\"\n",
    "    returna list\n",
    "    \"\"\"\n",
    "    \n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "\n",
    "    tracks = []\n",
    "    scores = []\n",
    "    desc = []\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        tracks.append(data.track_uri.loc[data.track_uri_id == idx].iloc[0])\n",
    "        scores.append(score)\n",
    "        #desc.append(D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]])\n",
    "\n",
    "    # Create a dataframe of artist names and scores\n",
    "    #recommendations = pd.DataFrame({'track_uris': tracks, 'score': scores})\n",
    "\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# CREATE SEED TRACKS FROM A PID\n",
    "#----------------------------------------------\n",
    "\n",
    "def get_seed_tracks(pid):\n",
    "    pid_id = pid\n",
    "    print(f'Seed tracks from pid {pid_id}')\n",
    "    # Use the implicit recommender.\n",
    "    I = {}\n",
    "    for el in data[data.pid == pid_id].track_uri.unique():\n",
    "        I[el] = D_desc[el]\n",
    "    \n",
    "#     recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "    \n",
    "#     R = {}\n",
    "\n",
    "#     for item in recommended:\n",
    "#         idx, score = item\n",
    "#         R[data.track_uri.loc[data.track_uri_id == idx].iloc[0]] = D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]]\n",
    "    \n",
    "    return list(I.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# CREATE USER RECOMMENDATIONS WITH DESCRIPTION\n",
    "#----------------------------------------------\n",
    "\n",
    "def create_recs_with_description(pid,N):\n",
    "    pid_id = pid\n",
    "    print(f'Recommendations for {pid_id}')\n",
    "#     # Use the implicit recommender.\n",
    "#     I = {}\n",
    "#     for el in data[data.pid == pid_id].track_uri.unique():\n",
    "#         I[el] = D_desc[el]\n",
    "    \n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "    \n",
    "    R = {}\n",
    "\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        R[data.track_uri.loc[data.track_uri_id == idx].iloc[0]] = D_desc[data.track_uri.loc[data.track_uri_id == idx].iloc[0]]\n",
    "    \n",
    "    return list(R.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# CREATE USER RECOMMENDATIONS WITH DICTIONARY OUTPUT\n",
    "#---------------------------------------------------\n",
    "def create_recs_dictionary_output(pid,N):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        pid\n",
    "        N - \n",
    "    output: \n",
    "        reccomendation dictionary {track_uri: score}\n",
    "    \"\"\"\n",
    "    \n",
    "    pid_id = pid\n",
    "\n",
    "    # Use the implicit recommender.\n",
    "    recommended = model.recommend(pid_id, sparse_user_item, N=N)\n",
    "\n",
    "    rec_tracks = {}\n",
    "\n",
    "    # Get artist names from ids\n",
    "    for item in recommended:\n",
    "        idx, score = item\n",
    "        rec_tracks[D_track_id_to_uri[idx]] = score\n",
    "\n",
    "    return rec_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------\n",
    "# GET RECOMMENDATIONS AND EVALUATE\n",
    "#----------------------------------\n",
    "\n",
    "def als_predict_and_evaluate_top_n(pid, top_n=100):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        pid - playlist id\n",
    "        top_n - top_n recommendations\n",
    "    return\n",
    "        top_n predicted: track_ids\n",
    "        ground_truth : track_ids in the hold_out\n",
    "        R_Prec\n",
    "        NDGC\n",
    "    \"\"\"\n",
    "    L_pred = list(create_recs_dictionary_output(pid,top_n).keys())\n",
    "    \n",
    "    ground_truth = ev_set_arr[ev_set_arr[:,0]==pid][:,1]\n",
    "    \n",
    "    R_Prec = R_Precision(L_pred[:len(ground_truth)],ground_truth)\n",
    "    \n",
    "    res = [int(el in ground_truth) for el in L_pred]\n",
    "    \n",
    "    NDCG = nDCG(res)[1]\n",
    "    \n",
    "    return L_pred, ground_truth, R_Prec, NDCG, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------\n",
    "# SAVE R-PRECISION AND NDCG BY PID\n",
    "#-----------------------------------\n",
    "\n",
    "def save_als_res_k_n(n = 10, top_n=20):\n",
    "    \"\"\"\n",
    "    k = number of factors\n",
    "    n= number of random lists to predict\n",
    "    \"\"\"\n",
    "    time0=time()\n",
    "    RES={}\n",
    "    ep = random.sample(evaluation_pids,n)\n",
    "    for i,pid in enumerate(ep):\n",
    "        predictions=als_predict_and_evaluate_top_n(pid,top_n)\n",
    "        RES[pid] = [predictions[2], predictions[3]]\n",
    "        if i % 500 ==0:\n",
    "            print(i)\n",
    "            print(time()-time0)\n",
    "    df = pd.DataFrame(RES).transpose().reset_index()\n",
    "    df.columns=['pid','R-Precision','nDCG']\n",
    "    df['rating'] = 'pos'\n",
    "    df['model'] = f'ALS'\n",
    "    df.to_csv(f'../evaluation/ALS_pos_topn_{top_n}_{n}.csv', index = None)\n",
    "    print(time()-time0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_track_artist(name, entity):\n",
    "    S = []\n",
    "    if entity == 'track':\n",
    "        for k, v in D_desc.items():\n",
    "            if v[0].lower().find(name.lower()) !=-1:\n",
    "                S.append([k, v])\n",
    "    if entity == 'artist':\n",
    "        for k, v in D_desc.items():\n",
    "            if v[1].lower().find(name.lower()) !=-1:\n",
    "                S.append([k, v])     \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data-processed/full-data/pid-track-pos-rating-train-data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data like we did before\n",
    "raw_data = pd.read_csv(file_path)\n",
    "# raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns = ['pid', 'track_uri', 'rating']\n",
    "data = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric user_id and artist_id column\n",
    "data['pid'] = data['pid'].astype(\"category\")\n",
    "data['track_uri'] = data['track_uri'].astype(\"category\")\n",
    "data['pid_id'] = data['pid'].cat.codes\n",
    "data['track_uri_id'] = data['track_uri'].cat.codes\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_track_id = data.groupby('track_uri')['track_uri_id'].min().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_track_id_to_uri = {}\n",
    "for k,v in D_track_id.items():\n",
    "    D_track_id_to_uri[v] = k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The implicit library expects data as a item-user matrix so we\n",
    "# create two matricies, one for fitting the model (item-user) \n",
    "# and one for recommendations (user-item)\n",
    "sparse_item_user = sparse.csr_matrix((data['rating'].astype(float), (data['track_uri_id'], data['pid_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((data['rating'].astype(float), (data['pid_id'], data['track_uri_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "# Initialize the als model and fit it using the sparse item-user matrix\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.1, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db4fa37d27f4701aa4620176819d0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionary with tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lose Control (feat. Ciara & Fat Man Scoop)', 'Missy Elliott', 'The Cookbook']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data-processed/full-data/track_descriptions.json') as json_file:\n",
    "    D_desc = json.load(json_file)\n",
    "    \n",
    "D_desc['spotify:track:0UaMYEvWZi0ZqiDOoHU3YI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = pd.read_csv('../data-processed/full-data/evaluation-pids-ground-truth.csv')\n",
    "evaluation_set.head()\n",
    "\n",
    "ev_set = evaluation_set[evaluation_set['hold_out'] == 1][['pid','track_uri','hold_out']]\n",
    "ev_set = ev_set[ev_set.isnull()==False]\n",
    "\n",
    "ev_set_arr = ev_set.to_numpy()\n",
    "\n",
    "evaluation_pids = list(ev_set.pid.unique())\n",
    "\n",
    "# ev_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `~~~~~~~~~~~~~~~~~~~~~~~~~~~ DEMO TIME~~~~~~~~~~~~~~~~~~~~~~~~~~~`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"tenor.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for track or artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spotify:track:4NnWuGQujzWUEg0uZokO5M',\n",
       "  ['Just Like Heaven', 'The Cure', 'Kiss Me, Kiss Me, Kiss Me']],\n",
       " ['spotify:track:4QlzkaRHtU8gAdwqjWmO8n',\n",
       "  [\"Friday I'm In Love\", 'The Cure', 'Wish']],\n",
       " ['spotify:track:0X5C4WjQNubRysTkHOubz3',\n",
       "  ['Lovesong', 'The Cure', 'Disintegration']],\n",
       " ['spotify:track:1QFh8OH1e78dGd3VyJZCAC',\n",
       "  [\"Boys Don't Cry\", 'The Cure', 'Three Imaginary Boys']],\n",
       " ['spotify:track:0T6kwiueP62ten2KLLmQS4',\n",
       "  ['A Forest', 'The Cure', 'Seventeen Seconds']]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_or_artist = 'the cure'\n",
    "entity = 'artist'\n",
    "results_to_print = 5\n",
    "search_track_artist(track_or_artist, entity)[0:results_to_print]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF ALS pos - first track returned is the seed track\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Friday I'm In Love\", 'The Cure', 'Wish'],\n",
       " ['Just Like Heaven', 'The Cure', 'Kiss Me, Kiss Me, Kiss Me'],\n",
       " ['Blister in the Sun - 2002 Remastered Version',\n",
       "  'Violent Femmes',\n",
       "  'Violent Femmes'],\n",
       " ['I Melt With You', 'Modern English', 'Pillow Lips'],\n",
       " ['Love It When You Call', 'The Feeling', 'Twelve Stops and Home'],\n",
       " [\"What's Up?\", '4 Non Blondes', 'Bigger, Better, Faster, More !'],\n",
       " ['When The Stars Go Blue - feat. Bono Disclab Remix',\n",
       "  'The Corrs',\n",
       "  'Dreams - The Ultimate Corrs Collection'],\n",
       " ['Lovesong', 'The Cure', 'Disintegration'],\n",
       " ['Everybody Wants To Rule The World',\n",
       "  'Tears For Fears',\n",
       "  'Songs From The Big Chair'],\n",
       " [\"Don't Dream It's Over\", 'Crowded House', 'Crowded House'],\n",
       " ['There She Goes', \"The La's\", \"The La's\"],\n",
       " ['Birdhouse In Your Soul', 'They Might Be Giants', 'Flood'],\n",
       " ['I Melt With You (7\" Mix)', 'Modern English', 'After the Snow'],\n",
       " ['Crash', 'The Primitives', 'Lovely'],\n",
       " ['Dreams', 'The Cranberries', \"Everybody Else Is Doing It, So Why Can't We?\"],\n",
       " [\"Boys Don't Cry\", 'The Cure', 'Three Imaginary Boys']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_items_with_description('spotify:track:4QlzkaRHtU8gAdwqjWmO8n',15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a playlist continuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed tracks from pid 59701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[\"Sarah's Song\", 'Ricky Hil', 'SYLDD'],\n",
       " ['I Know', 'Big Sean', 'Dark Sky Paradise'],\n",
       " ['Swimming Pools (Drank) - Extended Version',\n",
       "  'Kendrick Lamar',\n",
       "  'good kid, m.A.A.d city'],\n",
       " ['Alright', 'Logic', 'Under Pressure'],\n",
       " ['Low Life', 'Future', 'EVOL'],\n",
       " ['Already', 'Kodak Black', 'Institution'],\n",
       " ['False Alarm', 'The Weeknd', 'Starboy'],\n",
       " ['Starboy', 'The Weeknd', 'Starboy'],\n",
       " ['Murder', 'ShredGang', 'Shred Gang'],\n",
       " ['You Got Me', 'G-Eazy', \"When It's Dark Out\"],\n",
       " ['All Me', 'Drake', 'Nothing Was The Same'],\n",
       " ['No Role Modelz', 'J. Cole', '2014 Forest Hills Drive'],\n",
       " ['Wet Dreamz', 'J. Cole', '2014 Forest Hills Drive'],\n",
       " ['A Tale of 2 Citiez', 'J. Cole', '2014 Forest Hills Drive'],\n",
       " ['Turnt (feat. Sweezee Don)', 'Dame Dot', '3rd World'],\n",
       " ['Forbidden Fruit', 'J. Cole', 'Born Sinner'],\n",
       " ['Sidewalks', 'The Weeknd', 'Starboy'],\n",
       " ['I Feel It Coming', 'The Weeknd', 'Starboy'],\n",
       " ['Broken', 'Lund', 'Broken'],\n",
       " ['Clubhouse', 'Mac Miller', 'GO:OD AM'],\n",
       " ['Bad and Boujee (feat. Lil Uzi Vert)', 'Migos', 'Culture'],\n",
       " ['434am', 'Aftertheparty', '?!'],\n",
       " ['Ghost Stories', 'Anthony Russo', 'Ghost Stories'],\n",
       " ['Really? Yeah!', 'KYLE', 'Smyle'],\n",
       " ['Swish', 'Mike Stud', 'These Days'],\n",
       " ['Real Girls Get Down on the Floor',\n",
       "  'Sean Leon',\n",
       "  'Narcissus, the Drowning of Ego'],\n",
       " ['Uber Everywhere', 'MadeinTYO', 'Uber Everywhere'],\n",
       " ['KMT', 'Drake', 'More Life'],\n",
       " ['Sacrifices', 'Drake', 'More Life'],\n",
       " ['No Long Talk', 'Drake', 'More Life'],\n",
       " ['Skepta Interlude', 'Drake', 'More Life'],\n",
       " ['Power Trip', 'J. Cole', 'Born Sinner'],\n",
       " ['Rich Niggaz', 'J. Cole', 'Born Sinner'],\n",
       " ['Land of the Snakes', 'J. Cole', 'Born Sinner'],\n",
       " ['Energy', 'Drake', \"If You're Reading This It's Too Late\"],\n",
       " ['DAMN', 'lil aaron', 'DAMN'],\n",
       " [\"It's Luh\", 'Derek Luh', 'Hollywood Blvd'],\n",
       " ['Leanworld', 'Yung Lean', 'Unknown Memory']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = random.sample(evaluation_pids,1)[0]\n",
    "get_seed_tracks(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 59701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['White Iverson', 'Post Malone', 'Stoney'],\n",
       " [\"Don't\", 'Bryson Tiller', 'T R A P S O U L'],\n",
       " ['Fake Love', 'Drake', 'More Life'],\n",
       " ['Go Flex', 'Post Malone', 'Stoney'],\n",
       " ['V. 3005', 'Childish Gambino', 'because the internet'],\n",
       " ['Chill Bill', 'Rob $tone', 'Chill Bill'],\n",
       " ['What They Want', 'Russ', \"There's Really A Wolf\"],\n",
       " ['Exchange', 'Bryson Tiller', 'T R A P S O U L'],\n",
       " ['Father Stretch My Hands Pt. 1', 'Kanye West', 'The Life Of Pablo'],\n",
       " ['No Problem (feat. Lil Wayne & 2 Chainz)',\n",
       "  'Chance The Rapper',\n",
       "  'Coloring Book'],\n",
       " ['Caroline', 'Amin√©', 'Good For You'],\n",
       " ['goosebumps', 'Travis Scott', 'Birds In The Trap Sing McKnight'],\n",
       " ['Deja Vu', 'J. Cole', '4 Your Eyez Only'],\n",
       " ['G.O.M.D.', 'J. Cole', '2014 Forest Hills Drive'],\n",
       " ['One Night', 'Lil Yachty', 'Lil Boat'],\n",
       " ['IV. sweatpants', 'Childish Gambino', 'because the internet'],\n",
       " ['Broccoli (feat. Lil Yachty)', 'DRAM', 'Big Baby DRAM'],\n",
       " ['Antidote', 'Travis Scott', 'Rodeo'],\n",
       " ['Congratulations', 'Post Malone', 'Stoney'],\n",
       " ['Bounce Back', 'Big Sean', 'I Decided.']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_recs_with_description(inp, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = save_als_res_k_n(10000,500)\n",
    "# df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
